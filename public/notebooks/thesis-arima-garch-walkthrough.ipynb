{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Masterthesis Walkthrough Notebook\n",
        "\n",
        "**Titel:** Evaluating the ARIMA-GARCH Model's Accuracy Across Diverse Cryptocurrencies  \n",
        "**Autor:** Markus Öffel  \n",
        "**Assets:** BTC, ETH, DOGE, SOL  \n",
        "**Zeitraum:** 2020-05-11 bis 2024-04-20\n",
        "\n",
        "Dieses Notebook ist die strukturierte, schrittweise Reproduktion deines Thesis-Workflows in kleinen Theorie- und Codehappen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Zielbild dieses Notebooks\n",
        "\n",
        "Wir bauen den Workflow in klaren Blöcken auf:\n",
        "\n",
        "1. Daten holen und prüfen  \n",
        "2. Log-Returns und Splits erstellen  \n",
        "3. Diagnostik (ADF/KPSS, Ljung-Box, ARCH-LM)  \n",
        "4. ARIMA + GARCH-Familie fitten  \n",
        "5. Rolling Backtests und Multi-Horizon Evaluation  \n",
        "6. DM-Tests und VaR-Backtests (Kupiec/Christoffersen)  \n",
        "7. Resultate interpretieren und exportieren"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Bezug zum Originalcode\n",
        "\n",
        "Dieses Notebook basiert auf dem Originalskript:\n",
        "\n",
        "- `ARIMA GARCH FINAL.py` (v28.5)\n",
        "\n",
        "Inhaltlich übernommen wurden u. a.:\n",
        "\n",
        "- Konfigurationslogik (Assets, Zeitraum, Horizonte, Rolling Window)  \n",
        "- ARIMA-GARCH Modellfamilien  \n",
        "- EWMA-Benchmark  \n",
        "- Diebold-Mariano Tests  \n",
        "- Parametrische VaR/ES + Kupiec/Christoffersen Backtests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Core-Konfiguration aus der Thesis (leicht reduziert auf Notebook-Flow)\n",
        "THESIS_CONFIG = {\n",
        "    \"symbols\": {\n",
        "        \"bitcoin\": \"BTC-USD\",\n",
        "        \"ethereum\": \"ETH-USD\",\n",
        "        \"dogecoin\": \"DOGE-USD\",\n",
        "        \"solana\": \"SOL-USD\",\n",
        "    },\n",
        "    \"start_date\": \"2020-05-11\",\n",
        "    \"end_date\": \"2024-04-20\",\n",
        "    \"split_ratios\": (0.70, 0.15, 0.15),\n",
        "    \"horizons\": [1, 3, 7, 14, 30],\n",
        "    \"rolling_window\": 60,\n",
        "    \"robustness_window\": 365,\n",
        "    \"refit_interval\": 1,\n",
        "    \"ewma_lambda\": 0.94,\n",
        "    \"dm_alpha\": 0.05,\n",
        "    \"var_alpha\": 0.05,\n",
        "}\n",
        "\n",
        "THESIS_CONFIG"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Pakete und Reproduzierbarkeit\n",
        "\n",
        "Wenn einzelne Pakete fehlen, installiere sie in deiner Notebook-Umgebung (z. B. via `pip install ...`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "from scipy.stats import norm, t as student_t, chi2\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller, kpss\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox, het_arch\n",
        "from arch import arch_model\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "OUTPUT_DIR = Path(\"thesis_notebook_outputs\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "print(\"Output directory:\", OUTPUT_DIR.resolve())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Datenerhebung aus Yahoo Finance\n",
        "\n",
        "Die Thesis nutzt tägliche Kurse (`Close`) und arbeitet danach mit Log-Returns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fetch_price_history(symbol: str, start_date: str, end_date: str) -> pd.DataFrame:\n",
        "    history = yf.download(symbol, start=start_date, end=end_date, auto_adjust=True, progress=False)\n",
        "    if history.empty:\n",
        "        raise ValueError(f\"No data returned for {symbol}\")\n",
        "\n",
        "    frame = history[[\"Close\"]].copy()\n",
        "    frame = frame.rename(columns={\"Close\": \"close\"})\n",
        "    frame.index = pd.to_datetime(frame.index)\n",
        "    frame = frame.sort_index()\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_price_data: dict[str, pd.DataFrame] = {}\n",
        "\n",
        "for asset_name, ticker_symbol in THESIS_CONFIG[\"symbols\"].items():\n",
        "    raw_price_data[asset_name] = fetch_price_history(\n",
        "        symbol=ticker_symbol,\n",
        "        start_date=THESIS_CONFIG[\"start_date\"],\n",
        "        end_date=THESIS_CONFIG[\"end_date\"],\n",
        "    )\n",
        "\n",
        "{asset_name: frame.shape for asset_name, frame in raw_price_data.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Quality Check\n",
        "\n",
        "Kleine Plausibilitätsprüfung vor dem Modellieren."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def profile_price_frame(price_frame: pd.DataFrame) -> dict:\n",
        "    return {\n",
        "        \"start\": price_frame.index.min(),\n",
        "        \"end\": price_frame.index.max(),\n",
        "        \"rows\": len(price_frame),\n",
        "        \"missing_close\": int(price_frame[\"close\"].isna().sum()),\n",
        "        \"min_close\": float(price_frame[\"close\"].min()),\n",
        "        \"max_close\": float(price_frame[\"close\"].max()),\n",
        "    }\n",
        "\n",
        "quality_report = pd.DataFrame(\n",
        "    {asset_name: profile_price_frame(price_frame) for asset_name, price_frame in raw_price_data.items()}\n",
        ").T\n",
        "\n",
        "quality_report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Log-Returns und Datensplits\n",
        "\n",
        "Wir nutzen:\n",
        "\n",
        "- `log_return_t = ln(P_t / P_{t-1})`\n",
        "- Split 70/15/15 in Train/Validation/Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_log_returns(price_frame: pd.DataFrame) -> pd.DataFrame:\n",
        "    frame = price_frame.copy()\n",
        "    frame[\"log_return\"] = np.log(frame[\"close\"] / frame[\"close\"].shift(1))\n",
        "    frame[\"squared_return\"] = frame[\"log_return\"] ** 2\n",
        "    return frame.dropna().copy()\n",
        "\n",
        "\n",
        "def split_by_ratio(series_frame: pd.DataFrame, split_ratios: tuple[float, float, float]):\n",
        "    train_ratio, validation_ratio, test_ratio = split_ratios\n",
        "    assert abs((train_ratio + validation_ratio + test_ratio) - 1.0) < 1e-9\n",
        "\n",
        "    n_total = len(series_frame)\n",
        "    train_end = int(n_total * train_ratio)\n",
        "    validation_end = train_end + int(n_total * validation_ratio)\n",
        "\n",
        "    train_frame = series_frame.iloc[:train_end].copy()\n",
        "    validation_frame = series_frame.iloc[train_end:validation_end].copy()\n",
        "    test_frame = series_frame.iloc[validation_end:].copy()\n",
        "    return train_frame, validation_frame, test_frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "asset_data: dict[str, dict[str, pd.DataFrame]] = {}\n",
        "\n",
        "for asset_name, price_frame in raw_price_data.items():\n",
        "    returns_frame = add_log_returns(price_frame)\n",
        "    train_frame, validation_frame, test_frame = split_by_ratio(\n",
        "        returns_frame,\n",
        "        THESIS_CONFIG[\"split_ratios\"],\n",
        "    )\n",
        "    asset_data[asset_name] = {\n",
        "        \"full\": returns_frame,\n",
        "        \"train\": train_frame,\n",
        "        \"validation\": validation_frame,\n",
        "        \"test\": test_frame,\n",
        "    }\n",
        "\n",
        "split_overview = pd.DataFrame(\n",
        "    {\n",
        "        asset_name: {\n",
        "            \"full\": len(parts[\"full\"]),\n",
        "            \"train\": len(parts[\"train\"]),\n",
        "            \"validation\": len(parts[\"validation\"]),\n",
        "            \"test\": len(parts[\"test\"]),\n",
        "        }\n",
        "        for asset_name, parts in asset_data.items()\n",
        "    }\n",
        ").T\n",
        "\n",
        "split_overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stationarität: ADF + KPSS\n",
        "\n",
        "**Theorie kurz:**\n",
        "\n",
        "- ADF Nullhypothese: Serie ist nicht stationär  \n",
        "- KPSS Nullhypothese: Serie ist stationär  \n",
        "\n",
        "Kombiniert geben beide Tests ein robusteres Bild."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_adf_kpss(series: pd.Series, adf_alpha: float = 0.05, kpss_alpha: float = 0.05) -> dict:\n",
        "    clean_series = series.dropna().astype(float)\n",
        "\n",
        "    adf_statistic, adf_p_value, *_ = adfuller(clean_series, autolag=\"AIC\")\n",
        "    kpss_statistic, kpss_p_value, *_ = kpss(clean_series, regression=\"c\", nlags=\"auto\")\n",
        "\n",
        "    return {\n",
        "        \"adf_stat\": adf_statistic,\n",
        "        \"adf_p_value\": adf_p_value,\n",
        "        \"adf_stationary\": bool(adf_p_value < adf_alpha),\n",
        "        \"kpss_stat\": kpss_statistic,\n",
        "        \"kpss_p_value\": kpss_p_value,\n",
        "        \"kpss_stationary\": bool(kpss_p_value >= kpss_alpha),\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "stationarity_results = pd.DataFrame(\n",
        "    {\n",
        "        asset_name: run_adf_kpss(parts[\"train\"][\"log_return\"])\n",
        "        for asset_name, parts in asset_data.items()\n",
        "    }\n",
        ").T\n",
        "\n",
        "stationarity_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Residual-Diagnostik: Ljung-Box + ARCH-LM\n",
        "\n",
        "**Theorie kurz:**\n",
        "\n",
        "- Ljung-Box prüft verbleibende Autokorrelation in Residuen  \n",
        "- ARCH-LM prüft verbleibende Heteroskedastizität"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_residual_diagnostics(residual_series: pd.Series, lb_lag: int = 20, arch_lag: int = 12) -> dict:\n",
        "    clean_series = residual_series.dropna().astype(float)\n",
        "\n",
        "    ljung_box_frame = acorr_ljungbox(clean_series, lags=[lb_lag], return_df=True)\n",
        "    arch_stat, arch_p_value, *_ = het_arch(clean_series, nlags=arch_lag)\n",
        "\n",
        "    return {\n",
        "        \"ljung_box_p\": float(ljung_box_frame[\"lb_pvalue\"].iloc[0]),\n",
        "        \"ljung_box_white_noise\": bool(ljung_box_frame[\"lb_pvalue\"].iloc[0] >= 0.05),\n",
        "        \"arch_lm_p\": float(arch_p_value),\n",
        "        \"arch_effect_present\": bool(arch_p_value < 0.05),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baselines für den Vergleich\n",
        "\n",
        "Wir nehmen dieselben Referenzen wie in der Thesis:\n",
        "\n",
        "- **Preis/Return:** Naive Forecast  \n",
        "- **Varianz:** EWMA mit `lambda=0.94`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def naive_return_forecast(last_observed_return: float, horizon: int) -> np.ndarray:\n",
        "    return np.repeat(last_observed_return, horizon)\n",
        "\n",
        "\n",
        "def ewma_variance(history_returns: pd.Series, lambda_value: float = 0.94) -> float:\n",
        "    clean_history = history_returns.dropna().astype(float)\n",
        "    if clean_history.empty:\n",
        "        return np.nan\n",
        "\n",
        "    variance_estimate = float(clean_history.var())\n",
        "    for observed_return in clean_history:\n",
        "        variance_estimate = lambda_value * variance_estimate + (1 - lambda_value) * (observed_return ** 2)\n",
        "    return variance_estimate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ARIMA-Order Tuning (Validation)\n",
        "\n",
        "Wir halten `d=0` für die Return-Serie und suchen `(p,q)` mit AIC-Kriterium."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tune_arima_order(return_series: pd.Series, max_p: int = 3, max_q: int = 3) -> tuple[tuple[int, int, int], float]:\n",
        "    clean_series = return_series.dropna().astype(float)\n",
        "\n",
        "    best_order = (1, 0, 1)\n",
        "    best_aic = np.inf\n",
        "\n",
        "    for ar_order in range(max_p + 1):\n",
        "        for ma_order in range(max_q + 1):\n",
        "            try:\n",
        "                model = ARIMA(clean_series, order=(ar_order, 0, ma_order), enforce_stationarity=False, enforce_invertibility=False)\n",
        "                fit_result = model.fit()\n",
        "                if fit_result.aic < best_aic:\n",
        "                    best_aic = float(fit_result.aic)\n",
        "                    best_order = (ar_order, 0, ma_order)\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    return best_order, best_aic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## GARCH-Familie Tuning (Validation)\n",
        "\n",
        "Wir testen dieselben Volatilitätsfamilien wie im Skript:\n",
        "\n",
        "- GARCH  \n",
        "- GJR  \n",
        "- FIGARCH  \n",
        "- EGARCH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_garch_model(residual_series: pd.Series, garch_type: str, distribution: str = \"t\"):\n",
        "    clean_residuals = residual_series.dropna().astype(float)\n",
        "    scaled_residuals = clean_residuals * 100.0\n",
        "\n",
        "    if garch_type == \"FIGARCH\":\n",
        "        model = arch_model(scaled_residuals, vol=\"FIGARCH\", p=1, q=1, dist=distribution, mean=\"Zero\", rescale=False)\n",
        "    elif garch_type == \"EGARCH\":\n",
        "        model = arch_model(scaled_residuals, vol=\"EGARCH\", p=1, o=1, q=1, dist=distribution, mean=\"Zero\", rescale=False)\n",
        "    elif garch_type == \"GJR\":\n",
        "        model = arch_model(scaled_residuals, vol=\"GARCH\", p=1, o=1, q=1, dist=distribution, mean=\"Zero\", rescale=False)\n",
        "    else:\n",
        "        model = arch_model(scaled_residuals, vol=\"GARCH\", p=1, q=1, dist=distribution, mean=\"Zero\", rescale=False)\n",
        "\n",
        "    return model.fit(disp=\"off\", show_warning=False)\n",
        "\n",
        "\n",
        "def tune_garch_family(residual_series: pd.Series) -> tuple[str, str, float]:\n",
        "    candidate_models = [\"GARCH\", \"GJR\", \"FIGARCH\", \"EGARCH\"]\n",
        "    candidate_distributions = [\"normal\", \"t\"]\n",
        "\n",
        "    best_combo = (\"GARCH\", \"t\", np.inf)\n",
        "\n",
        "    for candidate_model in candidate_models:\n",
        "        for candidate_distribution in candidate_distributions:\n",
        "            try:\n",
        "                fit_result = fit_garch_model(residual_series, candidate_model, distribution=candidate_distribution)\n",
        "                if fit_result.aic < best_combo[2]:\n",
        "                    best_combo = (candidate_model, candidate_distribution, float(fit_result.aic))\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "    return best_combo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ARIMA + GARCH Pipeline Fit\n",
        "\n",
        "Erst Mean-Modell (ARIMA), dann Volatilitätsmodell auf ARIMA-Residuen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ArimaGarchFit:\n",
        "    arima_order: tuple[int, int, int]\n",
        "    arima_result: any\n",
        "    garch_type: str\n",
        "    garch_distribution: str\n",
        "    garch_result: any\n",
        "\n",
        "\n",
        "def fit_arima_garch_pipeline(train_returns: pd.Series, validation_returns: pd.Series) -> ArimaGarchFit:\n",
        "    tuning_series = pd.concat([train_returns, validation_returns]).dropna().astype(float)\n",
        "\n",
        "    best_arima_order, _ = tune_arima_order(tuning_series)\n",
        "    arima_model = ARIMA(tuning_series, order=best_arima_order, enforce_stationarity=False, enforce_invertibility=False)\n",
        "    arima_result = arima_model.fit()\n",
        "\n",
        "    best_garch_type, best_garch_distribution, _ = tune_garch_family(arima_result.resid)\n",
        "    garch_result = fit_garch_model(arima_result.resid, best_garch_type, distribution=best_garch_distribution)\n",
        "\n",
        "    return ArimaGarchFit(\n",
        "        arima_order=best_arima_order,\n",
        "        arima_result=arima_result,\n",
        "        garch_type=best_garch_type,\n",
        "        garch_distribution=best_garch_distribution,\n",
        "        garch_result=garch_result,\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One-Step Forecast Helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def forecast_one_step(arima_garch_fit: ArimaGarchFit) -> tuple[float, float]:\n",
        "    mean_forecast = float(arima_garch_fit.arima_result.get_forecast(steps=1).predicted_mean.iloc[0])\n",
        "\n",
        "    garch_forecast = arima_garch_fit.garch_result.forecast(horizon=1, reindex=False)\n",
        "    variance_forecast_scaled = float(garch_forecast.variance.iloc[0, 0])\n",
        "    variance_forecast = max(variance_forecast_scaled / (100.0 ** 2), 0.0)\n",
        "\n",
        "    return mean_forecast, variance_forecast"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rolling Backtest (60 Tage)\n",
        "\n",
        "Backtest-Prinzip wie in der Thesis:\n",
        "\n",
        "- Rolling Fit Window (60)  \n",
        "- Refit je Schritt (`refit_interval=1`)  \n",
        "- Vergleich gegen Naive + EWMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_rolling_backtest(return_series: pd.Series, fitting_window: int, refit_interval: int = 1) -> pd.DataFrame:\n",
        "    clean_series = return_series.dropna().astype(float)\n",
        "    records: list[dict] = []\n",
        "\n",
        "    for current_index in range(fitting_window, len(clean_series) - 1):\n",
        "        window_series = clean_series.iloc[current_index - fitting_window:current_index]\n",
        "        actual_next_return = float(clean_series.iloc[current_index + 1])\n",
        "\n",
        "        if (current_index - fitting_window) % refit_interval == 0:\n",
        "            fit_bundle = fit_arima_garch_pipeline(window_series, pd.Series(dtype=float))\n",
        "\n",
        "        mean_forecast, variance_forecast = forecast_one_step(fit_bundle)\n",
        "        naive_forecast = float(window_series.iloc[-1])\n",
        "        ewma_variance_forecast = ewma_variance(window_series, lambda_value=THESIS_CONFIG[\"ewma_lambda\"])\n",
        "\n",
        "        records.append(\n",
        "            {\n",
        "                \"date\": clean_series.index[current_index + 1],\n",
        "                \"actual_return\": actual_next_return,\n",
        "                \"forecast_return_arima_garch\": mean_forecast,\n",
        "                \"forecast_return_naive\": naive_forecast,\n",
        "                \"forecast_variance_arima_garch\": variance_forecast,\n",
        "                \"forecast_variance_ewma\": ewma_variance_forecast,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return pd.DataFrame.from_records(records)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Horizon Evaluation (1/3/7/14/30)\n",
        "\n",
        "Für jede Forecast-Origin im Testset werden mehrere Horizonte geprüft."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_multi_horizon_static(arima_garch_fit: ArimaGarchFit, test_returns: pd.Series, horizons: list[int]) -> pd.DataFrame:\n",
        "    clean_series = test_returns.dropna().astype(float)\n",
        "    rows: list[dict] = []\n",
        "\n",
        "    max_horizon = max(horizons)\n",
        "    for origin_position in range(0, len(clean_series) - max_horizon):\n",
        "        origin_date = clean_series.index[origin_position]\n",
        "        base_return = float(clean_series.iloc[origin_position])\n",
        "\n",
        "        mean_forecast_series = arima_garch_fit.arima_result.get_forecast(steps=max_horizon).predicted_mean.values\n",
        "        variance_forecast_series = arima_garch_fit.garch_result.forecast(horizon=max_horizon, reindex=False).variance.iloc[0].values / (100.0 ** 2)\n",
        "\n",
        "        for horizon in horizons:\n",
        "            target_position = origin_position + horizon\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"origin_date\": origin_date,\n",
        "                    \"horizon\": horizon,\n",
        "                    \"actual_return\": float(clean_series.iloc[target_position]),\n",
        "                    \"arima_garch_return\": float(mean_forecast_series[horizon - 1]),\n",
        "                    \"naive_return\": base_return,\n",
        "                    \"arima_garch_variance\": float(max(variance_forecast_series[horizon - 1], 0.0)),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    return pd.DataFrame(rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diebold-Mariano Tests\n",
        "\n",
        "Wir testen jeweils die Prognosegüte-Differenz:\n",
        "\n",
        "- Preis/Return: ARIMA-GARCH vs Naive  \n",
        "- Varianz: ARIMA-GARCH vs EWMA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from dieboldmariano import dm_test\n",
        "    DIEBOLDMARIANO_AVAILABLE = True\n",
        "except Exception:\n",
        "    dm_test = None\n",
        "    DIEBOLDMARIANO_AVAILABLE = False\n",
        "\n",
        "\n",
        "def run_dm_test(actual_values: pd.Series, model_forecast: pd.Series, benchmark_forecast: pd.Series, horizon: int):\n",
        "    aligned = pd.concat(\n",
        "        [actual_values, model_forecast, benchmark_forecast],\n",
        "        axis=1,\n",
        "        keys=[\"actual\", \"model\", \"benchmark\"],\n",
        "    ).dropna()\n",
        "\n",
        "    if len(aligned) < 15:\n",
        "        return {\"error\": \"Too few observations\"}\n",
        "\n",
        "    if not DIEBOLDMARIANO_AVAILABLE:\n",
        "        return {\"error\": \"dieboldmariano package not installed\"}\n",
        "\n",
        "    statistic, p_value = dm_test(\n",
        "        aligned[\"actual\"].values,\n",
        "        aligned[\"model\"].values,\n",
        "        aligned[\"benchmark\"].values,\n",
        "        h=horizon,\n",
        "        one_sided=True,\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"dm_stat\": float(statistic),\n",
        "        \"p_value\": float(p_value),\n",
        "        \"significant\": bool(p_value < THESIS_CONFIG[\"dm_alpha\"]),\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VaR und ES (parametrisch)\n",
        "\n",
        "Für die Thesis wurde 5%-VaR im Modellvergleich genutzt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parametric_var_es(mean_forecast: float, variance_forecast: float, alpha: float = 0.05, distribution: str = \"normal\", dof: float | None = None):\n",
        "    sigma_forecast = np.sqrt(max(variance_forecast, 1e-12))\n",
        "\n",
        "    if distribution == \"t\" and dof is not None and dof > 2:\n",
        "        quantile = student_t.ppf(alpha, dof)\n",
        "        var_threshold = mean_forecast + quantile * sigma_forecast\n",
        "        expected_shortfall = mean_forecast - sigma_forecast * (student_t.pdf(quantile, dof) / alpha) * ((dof + quantile**2) / (dof - 1))\n",
        "    else:\n",
        "        quantile = norm.ppf(alpha)\n",
        "        var_threshold = mean_forecast + quantile * sigma_forecast\n",
        "        expected_shortfall = mean_forecast - sigma_forecast * norm.pdf(quantile) / alpha\n",
        "\n",
        "    return float(var_threshold), float(expected_shortfall)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## VaR Backtests: Kupiec + Christoffersen\n",
        "\n",
        "- **Kupiec** prüft die Trefferquote der VaR-Verletzungen  \n",
        "- **Christoffersen** ergänzt die Unabhängigkeit der Verletzungsserie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def kupiec_test(violations: np.ndarray, alpha: float = 0.05):\n",
        "    violation_count = int(violations.sum())\n",
        "    sample_size = len(violations)\n",
        "\n",
        "    if sample_size == 0:\n",
        "        return {\"error\": \"No observations\"}\n",
        "\n",
        "    observed_rate = violation_count / sample_size\n",
        "    observed_rate = np.clip(observed_rate, 1e-8, 1 - 1e-8)\n",
        "\n",
        "    log_likelihood_null = (sample_size - violation_count) * np.log(1 - alpha) + violation_count * np.log(alpha)\n",
        "    log_likelihood_alt = (sample_size - violation_count) * np.log(1 - observed_rate) + violation_count * np.log(observed_rate)\n",
        "\n",
        "    likelihood_ratio = -2 * (log_likelihood_null - log_likelihood_alt)\n",
        "    p_value = 1 - chi2.cdf(likelihood_ratio, df=1)\n",
        "\n",
        "    return {\"lr\": float(likelihood_ratio), \"p_value\": float(p_value), \"pass\": bool(p_value >= 0.05)}\n",
        "\n",
        "\n",
        "def christoffersen_independence_test(violations: np.ndarray):\n",
        "    if len(violations) < 2:\n",
        "        return {\"error\": \"Too few observations\"}\n",
        "\n",
        "    lagged = violations[:-1]\n",
        "    current = violations[1:]\n",
        "\n",
        "    n00 = int(((lagged == 0) & (current == 0)).sum())\n",
        "    n01 = int(((lagged == 0) & (current == 1)).sum())\n",
        "    n10 = int(((lagged == 1) & (current == 0)).sum())\n",
        "    n11 = int(((lagged == 1) & (current == 1)).sum())\n",
        "\n",
        "    pi0 = n01 / max(n00 + n01, 1)\n",
        "    pi1 = n11 / max(n10 + n11, 1)\n",
        "    pi = (n01 + n11) / max(n00 + n01 + n10 + n11, 1)\n",
        "\n",
        "    def safe_log(value: float) -> float:\n",
        "        return np.log(np.clip(value, 1e-12, 1 - 1e-12))\n",
        "\n",
        "    log_likelihood_independent = (n00 + n10) * safe_log(1 - pi) + (n01 + n11) * safe_log(pi)\n",
        "    log_likelihood_markov = n00 * safe_log(1 - pi0) + n01 * safe_log(pi0) + n10 * safe_log(1 - pi1) + n11 * safe_log(pi1)\n",
        "\n",
        "    likelihood_ratio = -2 * (log_likelihood_independent - log_likelihood_markov)\n",
        "    p_value = 1 - chi2.cdf(likelihood_ratio, df=1)\n",
        "\n",
        "    return {\"lr\": float(likelihood_ratio), \"p_value\": float(p_value), \"pass\": bool(p_value >= 0.05)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## End-to-End Runner pro Asset\n",
        "\n",
        "Diese Funktion orchestriert die Schritte in der Reihenfolge der Thesis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_asset_pipeline(asset_name: str, data_splits: dict[str, pd.DataFrame]):\n",
        "    train_returns = data_splits[\"train\"][\"log_return\"]\n",
        "    validation_returns = data_splits[\"validation\"][\"log_return\"]\n",
        "    test_returns = data_splits[\"test\"][\"log_return\"]\n",
        "\n",
        "    fit_bundle = fit_arima_garch_pipeline(train_returns, validation_returns)\n",
        "\n",
        "    rolling_input = pd.concat([train_returns, validation_returns, test_returns])\n",
        "    rolling_results = run_rolling_backtest(\n",
        "        return_series=rolling_input,\n",
        "        fitting_window=THESIS_CONFIG[\"rolling_window\"],\n",
        "        refit_interval=THESIS_CONFIG[\"refit_interval\"],\n",
        "    )\n",
        "\n",
        "    horizon_results = evaluate_multi_horizon_static(\n",
        "        arima_garch_fit=fit_bundle,\n",
        "        test_returns=test_returns,\n",
        "        horizons=THESIS_CONFIG[\"horizons\"],\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"fit_bundle\": fit_bundle,\n",
        "        \"rolling\": rolling_results,\n",
        "        \"horizon\": horizon_results,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Gesamtlauf für alle Assets\n",
        "\n",
        "> Der Lauf ist rechenintensiv. Für schnelles Arbeiten zuerst nur ein Asset starten (z. B. `bitcoin`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "RUN_FULL_EXPERIMENT = False\n",
        "ASSETS_TO_RUN = [\"bitcoin\"] if not RUN_FULL_EXPERIMENT else list(asset_data.keys())\n",
        "\n",
        "experiment_results = {}\n",
        "for asset_name in ASSETS_TO_RUN:\n",
        "    print(f\"Running pipeline for {asset_name}...\")\n",
        "    experiment_results[asset_name] = run_asset_pipeline(asset_name, asset_data[asset_name])\n",
        "\n",
        "list(experiment_results.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Robustness Check (365-Tage Window)\n",
        "\n",
        "Diese Zelle spiegelt den Robustness-Teil aus der Thesis (Fenstervergleich 60 vs 365)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_robustness_check(asset_name: str, data_splits: dict[str, pd.DataFrame]):\n",
        "    combined_returns = pd.concat(\n",
        "        [\n",
        "            data_splits[\"train\"][\"log_return\"],\n",
        "            data_splits[\"validation\"][\"log_return\"],\n",
        "            data_splits[\"test\"][\"log_return\"],\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    backtest_short_window = run_rolling_backtest(\n",
        "        return_series=combined_returns,\n",
        "        fitting_window=THESIS_CONFIG[\"rolling_window\"],\n",
        "        refit_interval=THESIS_CONFIG[\"refit_interval\"],\n",
        "    )\n",
        "\n",
        "    backtest_long_window = run_rolling_backtest(\n",
        "        return_series=combined_returns,\n",
        "        fitting_window=THESIS_CONFIG[\"robustness_window\"],\n",
        "        refit_interval=THESIS_CONFIG[\"refit_interval\"],\n",
        "    )\n",
        "\n",
        "    return backtest_short_window, backtest_long_window"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Ergebnis-Tabellen exportieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def export_result_tables(asset_name: str, result_bundle: dict):\n",
        "    rolling_path = OUTPUT_DIR / f\"{asset_name}_rolling_results.csv\"\n",
        "    horizon_path = OUTPUT_DIR / f\"{asset_name}_horizon_results.csv\"\n",
        "\n",
        "    result_bundle[\"rolling\"].to_csv(rolling_path, index=False)\n",
        "    result_bundle[\"horizon\"].to_csv(horizon_path, index=False)\n",
        "\n",
        "    return {\"rolling_csv\": str(rolling_path), \"horizon_csv\": str(horizon_path)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation (Thesis-nah)\n",
        "\n",
        "Beim Schreiben des Ergebnis-Kapitels helfen diese Leitfragen:\n",
        "\n",
        "1. Wo ist Return-Predictability statistisch signifikant?  \n",
        "2. Verbessert ARIMA-GARCH die Varianzprognose ggü. EWMA robust?  \n",
        "3. Besteht das Modell den 5%-VaR-Backtest pro Asset und pro Horizont?  \n",
        "4. Ändern sich Aussagen im Robustness-Check (365 statt 60 Tage)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_interpretation_summary(asset_name: str, result_bundle: dict) -> pd.DataFrame:\n",
        "    horizon_frame = result_bundle[\"horizon\"].copy()\n",
        "\n",
        "    summary_rows = []\n",
        "    for horizon in sorted(horizon_frame[\"horizon\"].dropna().unique()):\n",
        "        horizon_slice = horizon_frame[horizon_frame[\"horizon\"] == horizon]\n",
        "\n",
        "        row = {\n",
        "            \"asset\": asset_name,\n",
        "            \"horizon\": int(horizon),\n",
        "            \"n_obs\": len(horizon_slice),\n",
        "            \"mae_return_model\": float((horizon_slice[\"actual_return\"] - horizon_slice[\"arima_garch_return\"]).abs().mean()),\n",
        "            \"mae_return_naive\": float((horizon_slice[\"actual_return\"] - horizon_slice[\"naive_return\"]).abs().mean()),\n",
        "        }\n",
        "        summary_rows.append(row)\n",
        "\n",
        "    return pd.DataFrame(summary_rows)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Nächste Erweiterungen\n",
        "\n",
        "- Skewed Distributions (`skewt`, `skewnorm`) aus dem großen Skript wieder integrieren  \n",
        "- Vollständige Parameter-Tabellen (ARIMA + GARCH) als PNG/LaTeX-Export  \n",
        "- Multi-Asset Vergleichsgrafiken (Heatmaps) für DM- und VaR-Testresultate  \n",
        "- Notebook in Kapitel-Slices splitten (`01_data.ipynb`, `02_models.ipynb`, ...)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mapping Notebook ↔ Originalskript\n",
        "\n",
        "| Notebook-Block | Originalskript (v28.5) |\n",
        "|---|---|\n",
        "| Config und Setup | `CONFIG`, `CRYPTO_SYMBOLS` |\n",
        "| Data Fetch | `fetch_data_yahoo` |\n",
        "| Preprocessing | `preprocess_data`, `train_val_test_split` |\n",
        "| ARIMA/GARCH Fit | `fit_arima_garch` |\n",
        "| Forecasting | `forecast_arima_garch` |\n",
        "| DM Test | `diebold_mariano_test` |\n",
        "| VaR/ES + Backtests | `calculate_parametric_var_es`, `kupiec_test`, `christoffersen_test` |\n",
        "| Backtest/Horizon Loop | Main-Flow `backtest` und `horizon_evaluation` |\n",
        "\n",
        "Damit hast du eine nachvollziehbare, thesis-konforme Lern- und Demo-Version deines größten Projekts."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}