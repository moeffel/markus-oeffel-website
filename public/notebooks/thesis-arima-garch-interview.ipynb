{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interview Notebook — ARIMA-GARCH Thesis\n",
        "\n",
        "**Scope:** kompakte Version für Gespräch, Tech-Screening und Case-Deep-Dive.  \n",
        "**Assets:** BTC, ETH, DOGE, SOL  \n",
        "**Periode:** 2020-05-11 bis 2024-04-20"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Was dieses Notebook zeigt\n",
        "\n",
        "1. Datenzugriff und Return-Engineering  \n",
        "2. ARIMA (Mean) + GARCH (Volatility) in einem Pipeline-Schritt  \n",
        "3. Rolling Forecast-Konzept  \n",
        "4. Risiko-Validierung über 5% VaR Backtest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.12' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "CONFIG = {\n",
        "    \"symbol\": \"BTC-USD\",\n",
        "    \"start\": \"2020-05-11\",\n",
        "    \"end\": \"2024-04-20\",\n",
        "    \"split\": (0.70, 0.15, 0.15),\n",
        "    \"rolling_window\": 60,\n",
        "    \"var_alpha\": 0.05,\n",
        "    \"ewma_lambda\": 0.94,\n",
        "}\n",
        "\n",
        "CONFIG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.12' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "from scipy.stats import norm, chi2\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from arch import arch_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.12' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.12 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "def load_series(symbol: str, start: str, end: str) -> pd.DataFrame:\n",
        "    raw = yf.download(symbol, start=start, end=end, auto_adjust=True, progress=False)\n",
        "    data = raw[[\"Close\"]].rename(columns={\"Close\": \"close\"}).copy()\n",
        "    data[\"log_return\"] = np.log(data[\"close\"] / data[\"close\"].shift(1))\n",
        "    data[\"sq_return\"] = data[\"log_return\"] ** 2\n",
        "    return data.dropna()\n",
        "\n",
        "series = load_series(CONFIG[\"symbol\"], CONFIG[\"start\"], CONFIG[\"end\"])\n",
        "series.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_series(df: pd.DataFrame, split=(0.70, 0.15, 0.15)):\n",
        "    n = len(df)\n",
        "    n_train = int(n * split[0])\n",
        "    n_val = int(n * split[1])\n",
        "    train = df.iloc[:n_train]\n",
        "    val = df.iloc[n_train:n_train+n_val]\n",
        "    test = df.iloc[n_train+n_val:]\n",
        "    return train, val, test\n",
        "\n",
        "train, val, test = split_series(series, CONFIG[\"split\"])\n",
        "pd.Series({\"train\": len(train), \"val\": len(val), \"test\": len(test)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fit_arima_garch(returns: pd.Series, arima_order=(1,0,1), garch_type=\"FIGARCH\", dist=\"t\"):\n",
        "    r = returns.dropna().astype(float)\n",
        "\n",
        "    arima_res = ARIMA(r, order=arima_order, enforce_stationarity=False, enforce_invertibility=False).fit()\n",
        "    resid_scaled = arima_res.resid * 100.0\n",
        "\n",
        "    if garch_type == \"FIGARCH\":\n",
        "        garch = arch_model(resid_scaled, vol=\"FIGARCH\", p=1, q=1, dist=dist, mean=\"Zero\", rescale=False)\n",
        "    elif garch_type == \"EGARCH\":\n",
        "        garch = arch_model(resid_scaled, vol=\"EGARCH\", p=1, o=1, q=1, dist=dist, mean=\"Zero\", rescale=False)\n",
        "    elif garch_type == \"GJR\":\n",
        "        garch = arch_model(resid_scaled, vol=\"GARCH\", p=1, o=1, q=1, dist=dist, mean=\"Zero\", rescale=False)\n",
        "    else:\n",
        "        garch = arch_model(resid_scaled, vol=\"GARCH\", p=1, q=1, dist=dist, mean=\"Zero\", rescale=False)\n",
        "\n",
        "    garch_res = garch.fit(disp=\"off\", show_warning=False)\n",
        "    return arima_res, garch_res\n",
        "\n",
        "fit_returns = pd.concat([train[\"log_return\"], val[\"log_return\"]])\n",
        "arima_res, garch_res = fit_arima_garch(fit_returns)\n",
        "\n",
        "{\n",
        "    \"arima_aic\": float(arima_res.aic),\n",
        "    \"garch_aic\": float(garch_res.aic),\n",
        "    \"n_obs\": int(len(fit_returns)),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_step_forecast(arima_res, garch_res):\n",
        "    mean_fc = float(arima_res.get_forecast(steps=1).predicted_mean.iloc[0])\n",
        "    var_fc_scaled = float(garch_res.forecast(horizon=1, reindex=False).variance.iloc[0, 0])\n",
        "    var_fc = max(var_fc_scaled / (100.0 ** 2), 0.0)\n",
        "    return mean_fc, var_fc\n",
        "\n",
        "mu_1d, var_1d = one_step_forecast(arima_res, garch_res)\n",
        "mu_1d, var_1d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rmse(y_true, y_pred):\n",
        "    y_true = np.asarray(y_true, dtype=float)\n",
        "    y_pred = np.asarray(y_pred, dtype=float)\n",
        "    return float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
        "\n",
        "def qlike(actual_var, forecast_var, eps=1e-8):\n",
        "    a = np.asarray(actual_var, dtype=float)\n",
        "    f = np.asarray(forecast_var, dtype=float)\n",
        "    a = np.clip(a, eps, None)\n",
        "    f = np.clip(f, eps, None)\n",
        "    return float(np.mean((a / f) - np.log(a / f) - 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rolling_backtest(test_returns: pd.Series, full_returns: pd.Series, window=60):\n",
        "    full_r = full_returns.dropna().astype(float)\n",
        "    test_r = test_returns.dropna().astype(float)\n",
        "\n",
        "    start_idx = full_r.index.get_loc(test_r.index[0])\n",
        "    rows = []\n",
        "\n",
        "    for i in range(start_idx, len(full_r) - 1):\n",
        "        hist = full_r.iloc[max(0, i-window):i]\n",
        "        if len(hist) < window:\n",
        "            continue\n",
        "\n",
        "        ar, gr = fit_arima_garch(hist)\n",
        "        mu, var_model = one_step_forecast(ar, gr)\n",
        "\n",
        "        actual_next = float(full_r.iloc[i + 1])\n",
        "        naive_next = float(full_r.iloc[i])\n",
        "\n",
        "        ewma_var = float(hist.var())\n",
        "        for r in hist:\n",
        "            ewma_var = CONFIG[\"ewma_lambda\"] * ewma_var + (1 - CONFIG[\"ewma_lambda\"]) * (r ** 2)\n",
        "\n",
        "        rows.append({\n",
        "            \"date\": full_r.index[i + 1],\n",
        "            \"actual\": actual_next,\n",
        "            \"model_return\": mu,\n",
        "            \"naive_return\": naive_next,\n",
        "            \"actual_var\": actual_next ** 2,\n",
        "            \"model_var\": var_model,\n",
        "            \"ewma_var\": ewma_var,\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "bt = rolling_backtest(test[\"log_return\"], pd.concat([train[\"log_return\"], val[\"log_return\"], test[\"log_return\"]]), window=CONFIG[\"rolling_window\"])\n",
        "bt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parametric_var(mean, var, alpha=0.05):\n",
        "    sigma = np.sqrt(max(var, 1e-12))\n",
        "    return float(mean + norm.ppf(alpha) * sigma)\n",
        "\n",
        "def kupiec_pof(violations: np.ndarray, alpha=0.05):\n",
        "    x = int(violations.sum())\n",
        "    n = int(len(violations))\n",
        "    if n == 0:\n",
        "        return np.nan\n",
        "    p_hat = np.clip(x / n, 1e-8, 1 - 1e-8)\n",
        "    ll_h0 = (n - x) * np.log(1 - alpha) + x * np.log(alpha)\n",
        "    ll_h1 = (n - x) * np.log(1 - p_hat) + x * np.log(p_hat)\n",
        "    lr = -2 * (ll_h0 - ll_h1)\n",
        "    return float(1 - chi2.cdf(lr, 1))\n",
        "\n",
        "bt = bt.copy()\n",
        "bt[\"model_var_5\"] = bt.apply(lambda x: parametric_var(x[\"model_return\"], x[\"model_var\"], CONFIG[\"var_alpha\"]), axis=1)\n",
        "bt[\"ewma_var_5\"] = bt.apply(lambda x: parametric_var(0.0, x[\"ewma_var\"], CONFIG[\"var_alpha\"]), axis=1)\n",
        "\n",
        "viol_model = (bt[\"actual\"] < bt[\"model_var_5\"]).astype(int).values\n",
        "viol_ewma = (bt[\"actual\"] < bt[\"ewma_var_5\"]).astype(int).values\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"metric\": [\"RMSE return\", \"RMSE variance\", \"QLIKE variance\", \"Kupiec p-value\"],\n",
        "    \"ARIMA-GARCH\": [\n",
        "        rmse(bt[\"actual\"], bt[\"model_return\"]),\n",
        "        rmse(bt[\"actual_var\"], bt[\"model_var\"]),\n",
        "        qlike(bt[\"actual_var\"], bt[\"model_var\"]),\n",
        "        kupiec_pof(viol_model, CONFIG[\"var_alpha\"]),\n",
        "    ],\n",
        "    \"Benchmark\": [\n",
        "        rmse(bt[\"actual\"], bt[\"naive_return\"]),\n",
        "        rmse(bt[\"actual_var\"], bt[\"ewma_var\"]),\n",
        "        qlike(bt[\"actual_var\"], bt[\"ewma_var\"]),\n",
        "        kupiec_pof(viol_ewma, CONFIG[\"var_alpha\"]),\n",
        "    ],\n",
        "})\n",
        "\n",
        "summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Gesprächs-Storyline (2–3 Minuten)\n",
        "\n",
        "- **Problem:** 24/7-Volatilität in Krypto erschwert robuste Risikoabschätzung.  \n",
        "- **Ansatz:** ARIMA für Mean-Dynamik, GARCH-Familie für Volatilitätscluster.  \n",
        "- **Vergleich:** gegen Naive-Return und EWMA-Volatilität.  \n",
        "- **Validierung:** Rolling Backtest + VaR-Backtests (Kupiec).  \n",
        "- **Takeaway:** Return-Edge ist oft klein, Risk-Modelling-Mehrwert ist klarer."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
